{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random, exp, array, dot \n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "%matplotlib inline\n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self,x,y):\n",
    "        \n",
    "        # Seed the random generator \n",
    "        random.seed(1) \n",
    "        # random.seed fixes that random values so that answer is same\n",
    "        \n",
    "        # Save all variables in self for future references\n",
    "        self.x = x \n",
    "        self.y = y\n",
    "        self.x_shape = 784\n",
    "        self.y_shape = 10\n",
    "        self.layer_1_nodes = 4\n",
    "        self.layer_2_nodes = 5\n",
    "        self.layer_3_nodes = 3\n",
    "        \n",
    "        # generate weights with value -1 to 1\n",
    "        self.weights_1 = 2 * random.random((self.x_shape ,self.layer_1_nodes)) - 1\n",
    "        self.weights_2 = 2 * random.random((self.layer_1_nodes,self.layer_2_nodes)) - 1\n",
    "        self.weights_3 = 2 * random.random((self.layer_2_nodes, self.layer_3_nodes)) - 1\n",
    "        self.out_weights = 2 * random.random((self.layer_3_nodes, self.y_shape)) - 1\n",
    "        \n",
    "    # Sigmoid \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + exp(x))\n",
    "        \n",
    "    # Derivative sigmoid \n",
    "    def sigmoid_derivative(self,x):\n",
    "        return x * (1-x)\n",
    "        \n",
    "    def softmax(self,x):\n",
    "        return exp(x) / sum(exp(x))\n",
    "    \n",
    "    def softmax_derivative(self,x):\n",
    "        #https://deepnotes.io/softmax-crossentropy\n",
    "        pj = softmax = exp(x) / sum(exp(x))\n",
    "        \n",
    "        #derivative = del-pj / del-ai \n",
    "        derivative = pi * (1-pj) # if i = j \n",
    "        derivative = -pi * pj # if i != j\n",
    "        # How to write this code??? what are i and j \n",
    "            \n",
    "    def predict(self,x):\n",
    "        # Multiply the input weights and find it's sigmoid \n",
    "        print x.shape\n",
    "        print self.weights_1.shape\n",
    "        layer_1 = self.sigmoid(dot(x,self.weights_1)) #1 \n",
    "        layer_2 = self.sigmoid(dot(layer_1,self.weights_2)) #10 \n",
    "        layer_3 = self.sigmoid(dot(layer_2,self.weights_3)) #28\n",
    "        output = self.softmax(dot(layer_3,self.out_weights)) #28x10\n",
    "        print output.shape\n",
    "        return output\n",
    "    \n",
    "    # X -->(w1)  Z1 -->Sigmoid  A1 -->(w2) --> Z2 -->(softmax) Y\n",
    "    \n",
    "    # del(L) / del(w2)\n",
    "    # Z2 = W2.T * A1\n",
    "    # Z1 = W1.T * x\n",
    "    # A1 = sigmoid(z1)\n",
    "    # Y = sigmoid(Z2)\n",
    "    \n",
    "    \n",
    "    def train(self,num_steps):\n",
    "        errors = []\n",
    "        \n",
    "        # testing ka hain ye \n",
    "        # train karo naa ki predict\n",
    "        \n",
    "        for x in range(num_steps):\n",
    "            print x\n",
    "            \n",
    "            # FORWARD \n",
    "            layer_1 = self.sigmoid(dot(self.x,self.weights_1))\n",
    "            layer_2 = self.sigmoid(dot(layer_1,self.weights_2))\n",
    "            layer_3 = self.sigmoid(dot(layer_2,self.weights_3))\n",
    "            output = self.softmax(dot(layer_3,self.out_weights))\n",
    "            output_final = np.argmax(output,axis=1)\n",
    "#             print layer_1.shape\n",
    "#             print layer_2.shape\n",
    "#             print layer_3.shape\n",
    "#             print output.shape\n",
    "            \n",
    "            \n",
    "            # BACK PROPPOGATION \n",
    "            # Error\n",
    "            outputError = self.y  - output_final # y - ypred\n",
    "            print outputError\n",
    "            error = (outputError**2).sum() / (2 * self.y.shape[0])\n",
    "            errors.append(error)\n",
    "                \n",
    "            # delta = product of error and derivative of next layer\n",
    "            #check if required to take the derivative of SOFTMAX also??????\n",
    "            # only change in the derivative of output layer rest same\n",
    "            print output.shape, outputError.shape\n",
    "            delta  = outputError.dot(self.sigmoid_derivative(output))\n",
    "            # print self.sigmoid_derivative(output_final).shape\n",
    "            # print outputError.shape\n",
    "            \n",
    "            # Multiply with transpose of last layer\n",
    "            print 'Layer3 shape: ', layer_3.shape\n",
    "            print 'Delta shape:', delta.shape\n",
    "            out_weights_adjustment = dot(layer_3.T,delta) \n",
    "            print self.out_weights.shape\n",
    "            print out_weights_adjustment.shape\n",
    "            #self.out_weights = np.argmax(self.out_weights,axis=1)\n",
    "            self.out_weights +=  out_weights_adjustment #update weights\n",
    "                \n",
    "            # error = current_weight x delta in next layer\n",
    "            delta = dot(delta,self.out_weights.T) * self.sigmoid_derivative(layer_3)\n",
    "            weight_3_adjustment = dot(layer_2.T,delta)\n",
    "            self.weights_3 += weight_3_adjustment\n",
    "                \n",
    "            delta = dot(delta,self.weights_3.T) * self.sigmoid_derivative(layer_2)\n",
    "            weights_2_adjustment = dot(layer_1.T,delta)\n",
    "            self.weights_2 += weights_2_adjustment\n",
    "                \n",
    "            delta = dot(delta,self.weights_2.T) * self.sigmoid_derivative(layer_1)\n",
    "            weights_1_adjustment = dot(self.x.T,delta)\n",
    "            self.weights_1 += weights_1_adjustment\n",
    "        return errors                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    ds = pd.read_csv('../class_11/mnist/train.csv').values\n",
    "    #x_train = ds[:5000,1:].reshape((-1,1,28,28)) / 255.0\n",
    "    x_train = ds[:5000,1:]\n",
    "    y_train = ds[:5000,0]\n",
    "\n",
    "    #x_test = ds[5000:5002,1:].reshape(-1,1,28,28) / 255.0\n",
    "    x_test = ds[5000:5010,1:]\n",
    "    y_test = ds[5000:5010,0]\n",
    "    \n",
    "    \n",
    "#     err = neural_network.train(200)\n",
    "#     plt.plot(err)\n",
    "#     plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-4 -6 -7 ...,  2  7  9]\n",
      "(5000, 10) (5000,)\n",
      "Layer3 shape:  (5000, 3)\n",
      "Delta shape: (10,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,5000) and (10,) not aligned: 5000 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-8f8995ff09c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mneural_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mneural_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-177-dcf36a5f8d37>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_steps)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Layer3 shape: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m'Delta shape:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0mout_weights_adjustment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mout_weights_adjustment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,5000) and (10,) not aligned: 5000 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "neural_network = NeuralNet(x_train,y_train)\n",
    "neural_network.train(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n",
      "(784, 4)\n",
      "(10, 10)\n",
      "(10, 10)\n",
      "[8 3 8 6 6 5 3 6 6 3]\n",
      "[8 7 2 6 3 1 2 6 6 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "predictions = neural_network.predict(x_test) \n",
    "print predictions.shape\n",
    "output = np.argmax(predictions, axis=1)\n",
    "print output\n",
    "print y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = [40]%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (output == y_test).sum() * 100 / y_test.shape\n",
    "print 'Accuracy = ' + str(accuracy) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do this shape signify?\n",
    "# calculating the errors at end of training that are computed but what does this shape signify??\n",
    "\n",
    "#accuracy = (outs == y_test).sum()*100.0 / y_test.shape[0] \n",
    "\n",
    "\n",
    "# Converting MNIST images to numpy arrays    \n",
    "#     images_0 = []    \n",
    "#     for root,dire,filenames in os.walk(\"mnistasjpg/trainingSet/0/.\"):        \n",
    "#         for ix in range(1,100):\n",
    "#             im = io.imread('mnistasjpg/trainingSet/0/' + str(filenames[ix]))            \n",
    "#             images_0.append(im)\n",
    "    \n",
    "#     dataset = np.asarray(images_0)\n",
    "#     print dataset.shape\n",
    "#     x = dataset[0]\n",
    "#     y = np.array([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
